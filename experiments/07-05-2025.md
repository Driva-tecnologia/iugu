## Abordagens

* `1° Abordagem`: Utiliza o domínio website de cada CNPJ no Spiderwebv4 para que o HTML seja extraído. Após isso, o HTML é passado por uma etapa de limpeza e tokens são extraídos desse HTML utilizando TF-IDF (colocando um peso maior aos tokens que apareceram menos vezes). Os pesos dos tokens de cada domínio/CNPJ são utilizados para treinar um modelo de inteligência artificial.

* `2° Abordagem`: Utiliza o domínio website de cada CNPJ no Spiderwebv4 para que o HTML seja extraído. Após isso, o HTML é passado por uma etapa de limpeza e tokens são extraídos desse HTML utilizando TF-IDF (colocando um peso maior aos tokens que apareceram menos vezes). É obtido um peso para cada categoria de segmento e que é resultante da média dos tokens de cada CNPJ (exemplo: para o segmento educação, será feito o somatório dos pesos dos tokens para todos os CNPJs com esse rótulo e depois tirado a média), também chamado de vetor candidato. A inferência é feita utilizando esses vetores de candidatos para calcular as distâncias dado um vetor de referência (exemplo: um novo CNPJ), atribuindo o segmento que estiver mais próximo (menor distância dos vetores).

## Resultados

### 1) Utilizando apenas os dados da base enriquecida da Iugu (com os 20 samples) para treinamento

#### Apenas com os tokens do HTML

Abordagem 1:

* `Naive Bayes`: 0.5333 de F1-Score no conjunto de teste (4 samples de educação e 2 de Saas). Observação: todas as predições foram para o segmento Educação.
* `KNN`: 0.5333 de F1-Score no conjunto de teste (3 samples de educação, 1 de Saas e 1 de Saúde).
* `Random Forest`: 0.5333 de F1-Score no conjunto de teste (4 samples de educação e 2 de Saas). Observação: todas as predições foram para o segmento Educação.

Abordagem 2: 0.1667 de F1-Score no conjunto de teste (1 sample de educação, 1 de Saúde e 1 de Saas). Observação: todas as predições foram para o segmento Educação.

#### Usando tokens do HTML + dados do LinkedIn (about e slogan)

Abordagem 1:

* `Naive Bayes`: 0.5333 de F1-Score no conjunto de teste (4 samples de educação, 1 de Saúde e 1 de Saas). Observação: todas as predições foram para o segmento Educação.
* `KNN`: 0.45 de F1-Score no conjunto de teste (3 samples de educação, 1 de Saas e 1 de Saúde). Observação: todas as predições foram para o segmento Educação.
* `Random Forest`: 0.5333 de F1-Score no conjunto de teste (4 samples de educação, 1 de Saúde e 1 de Saas). Observação: todas as predições foram para o segmento Educação.

Abordagem 2: 0.1667 de F1-Score no conjunto de teste (1 sample de educação, 1 de Saúde e 1 de Saas). Observação: todas as predições foram para o segmento Educação.

### 2) Utilizando um base maior para treinamento e a base enriquecida da Iugu (com os 20 samples) para teste

Detalhes de como a base maior foi coletada:

* Utilizando as tabelas sites.vinculados (apenas aqueles com "vinculo_score" >= 0.7) e empresas_do_brasil.simplificado para coletar um grande volume de dados;
* Para filtrar esse grande volume, foram selecionados apenas as linhas onde CNAEs correspondia ao segmento de Educação, Saúde e Saas. Para isso, foi utilizada a coluna "CNAE Principal Divisão" com os valroes 85 e 86 para coletar dados dos segmentos de Educação e Saúde, respectivamente. Já para o segmento de Saas, foi utilizada a coluna "CNAE Principal Classe" com os valores 62023 e 62031;
* Devido ao grande volume, foram selecionados aleatoriamente 10 mil samples de cada segmento e que serão utilizados no Spiderwebv4;
* Foram domínios estranhos (exemplo: link para a página principal do Instagram ou do Facebook) e alguns casos que se repetiam. Para isso, foram removidos os domínios duplicados e estranhos.

#### Apenas com os tokens do HTML

Abordagem 1:

* `Naive Bayes`: 0.8615 de F1-Score no conjunto de teste e 0.7512 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       0.88      0.70      0.78        10\n'
 '        Saas       0.57      1.00      0.73         4\n'
 '       Saúde       1.00      0.50      0.67         2\n'
 '\n'
 '    accuracy                           0.75        16\n'
 '   macro avg       0.82      0.73      0.72        16\n'
 'weighted avg       0.81      0.75      0.75        16\n')

* `KNN`: 0.5565 de F1-Score no conjunto de teste e 0.2976 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       0.45      0.50      0.48        10\n'
 '        Saas       0.00      0.00      0.00         4\n'
 '       Saúde       0.00      0.00      0.00         2\n'
 '\n'
 '    accuracy                           0.31        16\n'
 '   macro avg       0.15      0.17      0.16        16\n'
 'weighted avg       0.28      0.31      0.30        16\n')

* `Random Forest`: 0.8536 de F1-Score no conjunto de teste e 0.6429 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       1.00      0.50      0.67        10\n'
 '        Saas       0.40      1.00      0.57         4\n'
 '       Saúde       1.00      0.50      0.67         2\n'
 '\n'
 '    accuracy                           0.62        16\n'
 '   macro avg       0.80      0.67      0.63        16\n'
 'weighted avg       0.85      0.62      0.64        16\n')

Abordagem 2: 0.8088 de F1-Score no conjunto de teste e 0.7604 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       1.00      0.60      0.75        10\n'
 '        Saas       0.50      1.00      0.67         4\n'
 '       Saúde       1.00      1.00      1.00         2\n'
 '\n'
 '    accuracy                           0.75        16\n'
 '   macro avg       0.83      0.87      0.81        16\n'
 'weighted avg       0.88      0.75      0.76        16\n')

#### Usando tokens do HTML + dados do LinkedIn (about e slogan)

Abordagem 1:

* `Naive Bayes`: 0.8658 de F1-Score no conjunto de teste e 0.2924 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       0.50      0.43      0.46         7\n'
 '        Saas       0.20      0.50      0.29         2\n'
 '       Saúde       0.00      0.00      0.00         4\n'
 '\n'
 '    accuracy                           0.31        13\n'
 '   macro avg       0.23      0.31      0.25        13\n'
 'weighted avg       0.30      0.31      0.29        13\n')

* `KNN`: 0.6665 de F1-Score no conjunto de teste e 0.1786 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       1.00      0.14      0.25         7\n'
 '        Saas       0.17      1.00      0.29         2\n'
 '       Saúde       0.00      0.00      0.00         4\n'
 '\n'
 '    accuracy                           0.23        13\n'
 '   macro avg       0.39      0.38      0.18        13\n'
 'weighted avg       0.56      0.23      0.18        13\n')

* `Random Forest`: 0.8826 de F1-Score no conjunto de teste e 0.41026 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       0.62      0.71      0.67         7\n'
 '        Saas       0.25      0.50      0.33         2\n'
 '       Saúde       0.00      0.00      0.00         4\n'
 '\n'
 '    accuracy                           0.46        13\n'
 '   macro avg       0.29      0.40      0.33        13\n'
 'weighted avg       0.38      0.46      0.41        13\n')

Abordagem 2: 0.8483 de F1-Score no conjunto de teste e 0.3812 de F1-Score nos dados da iugu.

('              precision    recall  f1-score   support\n'
 '\n'
 '    Educação       0.57      0.33      0.42        12\n'
 '        Saas       0.00      0.00      0.00         0\n'
 '       Saúde       0.50      0.20      0.29         5\n'
 '\n'
 '    accuracy                           0.29        17\n'
 '   macro avg       0.36      0.18      0.24        17\n'
 'weighted avg       0.55      0.29      0.38        17\n')
