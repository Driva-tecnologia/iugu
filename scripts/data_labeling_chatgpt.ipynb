{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "OPENAI_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import yake\n",
    "import nltk\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def parse_html(html):\n",
    "    if not html or html == '[]':\n",
    "        return \"\"\n",
    "\n",
    "    # Detecta string de bytes no formato hexadecimal\n",
    "    if isinstance(html, str):\n",
    "        hex_pattern = re.fullmatch(r'([0-9A-Fa-f]{2}(\\s+|$))+', html.strip())\n",
    "        if hex_pattern:\n",
    "            try:\n",
    "                byte_list = [int(x, 16) for x in html.strip().split()]\n",
    "                html = bytes(byte_list)\n",
    "            except Exception:\n",
    "                return \"\"\n",
    "\n",
    "    # Decodifica bytes para string UTF-8\n",
    "    if isinstance(html, bytes):\n",
    "        try:\n",
    "            html = html.decode('utf-8', erros='raise')\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    \n",
    "    # Faz o parsing com BeautifulSoup\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # Remove tags desnecessárias\n",
    "        for tag in soup([\"script\", \"style\", \"meta\", \"link\", \"noscript\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        # Extrai o texto e limpa\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        text = re.sub(r'\\b\\d+(\\.\\d+)?\\b', '', text)  # Removes numerical values (e.g., 123, 123.45)\n",
    "        text = re.sub(r'\\b\\d{1,2}h(\\d{2})?\\b', '', text)  # Remove hours (e.g., 12h30, 3h)\n",
    "        return text.strip()\n",
    "    except Exception:\n",
    "        return \"failed to parse HTML\"\n",
    "\n",
    "def extract_yake_keywords(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        kw_extractor = yake.KeywordExtractor(\n",
    "            lan=\"pt\",\n",
    "            n=1,\n",
    "            dedupLim=0.9,\n",
    "            top=100,\n",
    "            features=None\n",
    "        )\n",
    "        keywords = kw_extractor.extract_keywords(text)\n",
    "        return [kw[0].lower() for kw in keywords]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def extract_common_words(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        filtered_words = [word for word in words if word not in stopwords and len(word) > 2]\n",
    "        word_counts = Counter(filtered_words)\n",
    "        return [word[0].lower() for word in word_counts.most_common(100)]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def concatenate_keywords(html):\n",
    "    text = parse_html(html)\n",
    "\n",
    "    yake_keywords = extract_yake_keywords(text)\n",
    "    common_words = extract_common_words(text)\n",
    "    combined = []\n",
    "    max_length = max(len(yake_keywords), len(common_words))\n",
    "    for i in range(max_length):\n",
    "        if i < len(yake_keywords) and yake_keywords[i] not in combined:\n",
    "            combined.append(yake_keywords[i])\n",
    "        if i < len(common_words) and common_words[i] not in combined:\n",
    "            combined.append(common_words[i])\n",
    "    return combined[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da259ab2",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86486f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/novo_dado_iugu_enriquecimento.parquet\", engine=\"pyarrow\").reset_index(drop=True)\n",
    "df = df[[\"url\", \"host\", \"html\"]]\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c7cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"../data/IUGU Label - Base para enriquecimento.csv\").reset_index(drop=True)\n",
    "labels_df = labels_df.rename(columns={\"Site\": \"host\"})\n",
    "labels_df[\"host\"] = labels_df[\"host\"].str.replace(\"https://\", \"\")\n",
    "labels_df[\"host\"] = labels_df[\"host\"].str.replace(\".br/\", \".br\")\n",
    "labels_df[\"host\"] = labels_df[\"host\"].str.replace(\".com/\", \".com\")\n",
    "labels_df[\"host\"] = labels_df[\"host\"].str.replace(\".net/\", \".net\")\n",
    "labels_df[\"host\"] = labels_df[\"host\"].str.replace(\"www.\", \"\")\n",
    "labels_df[\"cnpj\"] = labels_df[\"cnpj\"].astype(str)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fab645",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = labels_df.merge(df, on=\"host\", how=\"left\")\n",
    "merged_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11457888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7aeb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"yake_keywords\"] = df[\"html\"].apply(concatenate_keywords)\n",
    "df[\"yake_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff17fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "TEST_LEN = 250\n",
    "BACKUP_PATH = \"../data/sample_classified.csv\"\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    @staticmethod\n",
    "    def _safe_get(value):\n",
    "        return value if value not in [None, \"\"] else \"Não informado\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _output_parser(content):\n",
    "        match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            json_string = match.group(0)\n",
    "            data = json.loads(json_string)\n",
    "            data = {k: data.get(k) for k in ['CNPJ', 'Segmento', 'Subsegmento', 'Nicho Tech']}\n",
    "            return data\n",
    "        else:\n",
    "            print(\"No JSON found\")\n",
    "\n",
    "    def prompt(self, row: pd.Series):\n",
    "        return f\"\"\" \n",
    "        Analise as informações abaixo sobre uma empresa e classifique-a em um dos seguintes segmentos, subsegmentos e nichos segundo as tabelas :\n",
    "\n",
    "        |  Segmento  \t|            Subsegmento            \t|\n",
    "        |:----------:\t|:---------------------------------:\t|\n",
    "        |    Agro    \t|            Agricultura            \t|\n",
    "        |    Agro    \t|            Outro (Agro)           \t|\n",
    "        |    Agro    \t|              Pecuária             \t|\n",
    "        |     Bet    \t|                Bet                \t|\n",
    "        |  Comércio  \t|              Atacado              \t|\n",
    "        |  Comércio  \t|          Outro (Comércio)         \t|\n",
    "        |  Comércio  \t|               Varejo              \t|\n",
    "        |  Educação  \t|          Educação básica          \t|\n",
    "        |  Educação  \t|        Educação Continuada        \t|\n",
    "        |  Educação  \t|         Educação Superior         \t|\n",
    "        |  Educação  \t|          Outro (Educação)         \t|\n",
    "        | Financeiro \t|               Banco               \t|\n",
    "        | Financeiro \t|              Cobrança             \t|\n",
    "        | Financeiro \t|             Corretora             \t|\n",
    "        | Financeiro \t|     Instituição de pagamentos     \t|\n",
    "        | Financeiro \t|        Mercado de capitais        \t|\n",
    "        | Financeiro \t|         Outro (Financeiro)        \t|\n",
    "        | Financeiro \t|             Seguradora            \t|\n",
    "        |  Indústria \t|            Alimentício            \t|\n",
    "        |  Indústria \t|            Eletricidade           \t|\n",
    "        |  Indústria \t|             Eletrônico            \t|\n",
    "        |  Indústria \t|             Hospitalar            \t|\n",
    "        |  Indústria \t|             Madeireira            \t|\n",
    "        |  Indústria \t|            Metalúrgica            \t|\n",
    "        |  Indústria \t|             Mineradora            \t|\n",
    "        |  Indústria \t|         Outro (Indústria)         \t|\n",
    "        |  Indústria \t|            Petrolífera            \t|\n",
    "        |  Indústria \t|              Químico              \t|\n",
    "        |    Outro   \t|           Outro (Outro)           \t|\n",
    "        |    Saas    \t|            Marketplace            \t|\n",
    "        |    Saas    \t|            Outro (Saas)           \t|\n",
    "        |    Saas    \t|             Plataforma            \t|\n",
    "        |    Saas    \t|              Software             \t|\n",
    "        |    Saúde   \t| Centro clínico ou rede de clínica \t|\n",
    "        |    Saúde   \t|         Cooperativa médica        \t|\n",
    "        |    Saúde   \t|              Hospital             \t|\n",
    "        |    Saúde   \t|    Operadora de planos de saúde   \t|\n",
    "        |    Saúde   \t|           Outro (Saúde)           \t|\n",
    "        |  Serviços  \t|              Agência              \t|\n",
    "        |  Serviços  \t|            Alimentação            \t|\n",
    "        |  Serviços  \t|            Consultoria            \t|\n",
    "        |  Serviços  \t|              Estatal              \t|\n",
    "        |  Serviços  \t|             Hotelaria             \t|\n",
    "        |  Serviços  \t|            Imobiliária            \t|\n",
    "        |  Serviços  \t|              Jurídico             \t|\n",
    "        |  Serviços  \t|          Outro (Serviços)         \t|\n",
    "        |  Serviços  \t|                T.I                \t|\n",
    "        |  Serviços  \t|          Telecomunicação          \t|\n",
    "\n",
    "        | Segmento \t|  Nicho Tech \t|\n",
    "        |:--------:\t|:-----------:\t|\n",
    "        |   Saas   \t|   Bettech   \t|\n",
    "        |   Saas   \t|    Edtech   \t|\n",
    "        |   Saas   \t|    Adtech   \t|\n",
    "        |   Saas   \t|   Agrotech  \t|\n",
    "        |   Saas   \t|   Biotech   \t|\n",
    "        |   Saas   \t| Construtech \t|\n",
    "        |   Saas   \t|  Energytech \t|\n",
    "        |   Saas   \t|   Fintech   \t|\n",
    "        |   Saas   \t|   Foodtech  \t|\n",
    "        |   Saas   \t|   Govtech   \t|\n",
    "        |   Saas   \t|    Hrtech   \t|\n",
    "        |   Saas   \t|   Indtech   \t|\n",
    "        |   Saas   \t|  Insurtech  \t|\n",
    "        |   Saas   \t|  Legaltech  \t|\n",
    "        |   Saas   \t|   Proptech  \t|\n",
    "        |   Saas   \t|  Retailtech \t|\n",
    "        |   Saas   \t|  Sporttech  \t|\n",
    "        |   Saas   \t|  Healthtech \t|\n",
    "        |   Saas   \t|  Outra tech \t|\n",
    "\n",
    "        Dados da empresa:\n",
    "\n",
    "        CNPJ: {self._safe_get(row.get('cnpj'))}\n",
    "        Nome: {self._safe_get(row.get('nome'))}\n",
    "        CNAE: {self._safe_get(row.get('cnae'))}\n",
    "        Domínio: {self._safe_get(row.get('url'))}\n",
    "        Tokens: {self._safe_get(row.get('yake_keywords'))}\n",
    "\n",
    "        Regras de classificação: \n",
    "            1) O SaaS deve ser o primeiro a ser classificado em relação aos outros segmentos, caso haja ambiguidade entre o segmento Saas e algum outro segmento. Vendo que uma determinada empresa não se enquadra como Saas, deve-se classifica-la dentro dos outros segmentos possíveis. A partir disso, classificar o subsegmento seguindo a tabela de referencia. Para as empresas classificadas como Saas, deve-se também, classificar o Nicho delas, seguindo a tabela de referencia de Segmento e Nicho Tech.\n",
    "            2) Na classificação, analise o html do site, e verifique se a partir dessas informações, é possível classificar o segmento e subsegmento da empresa. Caso haja alguma dúvida, utilize o CNAE como fator de desempate na classificação.\n",
    "            3) Se o site não tiver domínio e tokens, classifique-o de acordo com o CNAE e o nome. Não retorne uma saída vazia, o importante é classificar. Se não se encaixar em nenhum dos segmentos, colocar \"Não listado\" para todos os campos.\n",
    "            \n",
    "        Definições:\n",
    "            - SaaS, ou Software as a Service (Software como Serviço), é um modelo de software onde o fornecedor hospeda e mantém aplicações na nuvem, disponibilizando-as aos clientes por meio da internet, geralmente através de uma assinatura. Os clientes não precisam instalar ou gerenciar o software, acessando-o via navegador e pagando conforme o uso.\n",
    "            - Bettech: Bettech: Tecnologia voltada para o setor de apostas, tanto esportivas quanto de cassino, com foco em melhorar a experiência do usuário, segurança e análise de dados. Exemplos: Bet365, Betfair, Sportingbet.\n",
    "            - Edtech: Tecnologia aplicada à educação para facilitar o ensino e a aprendizagem por meio de plataformas digitais, apps e inteligência artificial. Exemplos: Duolingo, Khan Academy, Coursera.\n",
    "            - Adtech: Ferramentas e plataformas tecnológicas que otimizam campanhas de publicidade digital, como segmentação, análise de dados e automação. Exemplos: Google Ads, The Trade Desk, Taboola.\n",
    "            - Agrotech:\tSoluções tecnológicas aplicadas ao agronegócio para melhorar produtividade, sustentabilidade e gestão de recursos. Exemplos: Solinftec, Agrotools, John Deere (com tecnologia de agricultura de precisão).\n",
    "            - Biotech: Uso de processos biológicos e organismos vivos para desenvolver produtos e soluções, especialmente em saúde, genética e meio ambiente. Exemplos: Moderna, Biogen, Amgen.\n",
    "            - Construtech: Construtech: Inovações tecnológicas na construção civil, como software de gestão de obras, impressão 3D de estruturas e automação de processos. Exemplos: Construct App, 123Projetei, Ambar.\n",
    "            - Energytech: Tecnologias que otimizam a geração, distribuição, armazenamento ou uso de energia, especialmente renovável. Exemplos: Tesla Energy, Sonnen, Enphase.\n",
    "            - Fintech: Soluções tecnológicas no setor financeiro, como bancos digitais, pagamentos online, investimentos e seguros. Exemplos: Nubank, PicPay, Revolut.\n",
    "            - Foodtech:\tInovação tecnológica na produção, distribuição e consumo de alimentos, incluindo delivery, alimentos alternativos e rastreabilidade. Exemplos: iFood, Impossible Foods, NotCo.\n",
    "            - Govtech: Tecnologia voltada para melhorar os serviços públicos e a gestão governamental com mais eficiência e transparência. Exemplos: Colab, Portal da Transparência, Brasil Cidadão.\n",
    "            - Hrtech: Soluções tecnológicas aplicadas à gestão de recursos humanos, como recrutamento, folha de pagamento e engajamento de colaboradores. Exemplos: Gupy, Kenoby, Revelo.\n",
    "            - Indtech: Inovações tecnológicas no setor industrial, incluindo automação, IoT, robótica e monitoramento de processos. Exemplos: Siemens (com soluções industriais), Rockwell Automation, Embraer (com Indústria 4.0).\n",
    "            - Insurtech: Tecnologia aplicada ao setor de seguros, oferecendo produtos personalizados, automação de processos e melhoria na experiência do cliente. Exemplos: Youse, Pier, Lemonade.\n",
    "            - Legaltech: Uso da tecnologia para tornar os serviços jurídicos mais acessíveis, rápidos e eficientes. Exemplos: JusBrasil, LegalOne, Docket.\n",
    "            - Proptech: Soluções tecnológicas no setor imobiliário, como compra, aluguel e gestão de imóveis online. Exemplos: QuintoAndar, Loft, Zillow.\n",
    "            - Retailtech: Inovações no setor varejista, como e-commerce, automação de lojas, personalização e gestão de estoque. Exemplos: VTEX, Magalu, Shopify.\n",
    "            - Sporttech: Tecnologia aplicada ao esporte para melhorar desempenho de atletas, experiência do público e gestão de eventos esportivos. Strava, Catapult Sports, OneFootball.\n",
    "            - Healthtech: Soluções tecnológicas voltadas para saúde e bem-estar, como telemedicina, monitoramento remoto e prontuário eletrônico. Exemplos: Dr. Consulta, Teladoc Health, Vitalk.\n",
    "            - Outra tech: Qualquer plataforma que não se encaixe nas anteriores.\n",
    "\n",
    "        Exemplos de SaaS:\n",
    "            - Serviços de e-mail (como Google Workspace e Microsoft Office 365).\n",
    "            - Plataformas de CRM (como Salesforce e Zendesk).\n",
    "            - Ferramentas de produtividade e colaboração (como Slack, Trello e Asana).\n",
    "            - Plataformas de streaming (como Netflix e Spotify).\n",
    "            - Sistemas de ERP (como Oracle NetSuite e Conta Azul). \n",
    "\n",
    "        Responda, com base exclusivamente na estrutura da tabela apresentada, o CNPJ da empresa, o segmento, o subsegmento e o nicho tech apenas se o segmento for Saas (se não for deixar em branco), em formato JSON com as chaves 'CNPJ', 'Segmento', 'Subsegmento' e 'Nicho Tech', respectivamente.\n",
    "\n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    \n",
    "    def classify(self, row: pd.Series):\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": self.prompt(row)}\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            max_tokens=100,\n",
    "        )\n",
    "\n",
    "        data = self._output_parser(chat_completion.choices[0].message.content)\n",
    "        return data\n",
    "    \n",
    "        \n",
    "    async def parallel_classify(self, X: pd.DataFrame, batch_size: int=10, sleep=0.0):\n",
    "        \"\"\"Classifies data in batches asynchronously and yields it\"\"\"\n",
    "        \n",
    "        async_client = AsyncOpenAI(api_key=self.client.api_key)\n",
    "        all_results = {}\n",
    "\n",
    "        for batch_start in range(0, len(X), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X))\n",
    "            batch = X.iloc[batch_start:batch_end]\n",
    "\n",
    "            tasks = []\n",
    "            batch_indices = []\n",
    "\n",
    "            for idx, row in batch.iterrows():\n",
    "                prompt = [{'role': 'user', 'content': self.prompt(row)}]\n",
    "                task = async_client.chat.completions.create(\n",
    "                    messages=prompt,\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    temperature=0,\n",
    "                    max_tokens=100,\n",
    "                )\n",
    "                tasks.append(task)\n",
    "                batch_indices.append(idx)\n",
    "\n",
    "            # Execute batch asynchronously\n",
    "            batch_responses = await asyncio.gather(*tasks)\n",
    "\n",
    "            batch_results = {}\n",
    "            for idx, response in zip(batch_indices, batch_responses):\n",
    "                print(response.choices[0].message.content)\n",
    "                data = self._output_parser(response.choices[0].message.content)\n",
    "\n",
    "                batch_results[idx] = data\n",
    "                all_results[idx] = data\n",
    "\n",
    "            # Yield results per batch\n",
    "            yield pd.DataFrame.from_dict(batch_results, orient='index')\n",
    "\n",
    "            # Delay between batches\n",
    "            await asyncio.sleep(sleep)\n",
    "\n",
    "async def annotate(df, classifier, batch_size=50):\n",
    "    \"\"\"Yields batches of annotated data, including original DataFrame columns.\"\"\"\n",
    "    async for batch in classifier.parallel_classify(df, batch_size=batch_size):\n",
    "        # Create a DataFrame for the batch with original df index\n",
    "        annotated_batch = pd.DataFrame(batch, index=df.loc[batch.index].index)\n",
    "\n",
    "        yield annotated_batch\n",
    "\n",
    "def append_if_exists(df: pd.DataFrame, path: str):\n",
    "    \"\"\"Appends `df` to an existing file if it exists, otherwise creates a new file.\n",
    "    \n",
    "    Supports both CSV and Parquet formats. If a Parquet file is stored as a folder, it loads and appends correctly.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to append.\n",
    "        path (str): The file path, should end in .csv or .parquet.\n",
    "    \"\"\"\n",
    "    existing_df = load_file_if_exists(path)\n",
    "\n",
    "    if not existing_df is None:\n",
    "        df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "    # Save the DataFrame in the correct format\n",
    "    if path.endswith(\".csv\"):\n",
    "        print('saved at', path)\n",
    "        df.to_csv(path, index=False, sep=';')\n",
    "    elif path.endswith(\".parquet\"):\n",
    "        df.to_parquet(path, index=False)  # Will save as a folder if partitioning is used\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use .csv or .parquet\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_file_if_exists(path: str):\n",
    "    \"\"\"Checks and open a file if it exists.\n",
    "    \n",
    "    Supports both CSV and Parquet formats. If a Parquet file is stored as a folder, it loads and appends correctly.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The file path, should end in .csv or .parquet.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.exists(path) or os.path.isdir(path)  # Check if it's a folder (Parquet case)\n",
    "\n",
    "    if file_exists:\n",
    "        if path.endswith(\".csv\"):\n",
    "            existing_df = pd.read_csv(path, sep=';')\n",
    "        elif path.endswith(\".parquet\"):\n",
    "            existing_df = pd.read_parquet(path)  # Reads the folder as a Parquet dataset\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use .csv or .parquet\")\n",
    "        \n",
    "        return existing_df\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(api_key=OPENAI_KEY)\n",
    "samples = []\n",
    "# df = df.drop(columns=[\"Segmento iugu\", \"Nicho Tech\"])\n",
    "df_copy = df.copy()\n",
    "existing_samples = load_file_if_exists(BACKUP_PATH)\n",
    "\n",
    "# if not existing_samples is None:\n",
    "#     # excluding the samples that already were processed\n",
    "#     unique_domains = existing_samples[\"cnpj\"].unique().tolist()\n",
    "#     df = df[~df[\"cnpj\"].isin(unique_domains)].reset_index(drop=True)\n",
    "\n",
    "async for batch in annotate(df, classifier, batch_size=BATCH_SIZE):\n",
    "    samples.append(batch)\n",
    "    append_if_exists(batch, BACKUP_PATH)  # Append in batches\n",
    "    print(f'{min(BATCH_SIZE, len(batch))} classified samples were added to {BACKUP_PATH}')\n",
    "\n",
    "labeled_df = pd.concat(samples, axis=0)\n",
    "labeled_df = labeled_df.rename(columns={\"CNPJ\": \"cnpj\"})\n",
    "labeled_df_copy = labeled_df.copy()\n",
    "# labeled_df = labeled_df[labeled_df[\"Segmento\"] != \"Não listado\"].reset_index(drop=True)\n",
    "# labeled_df = labeled_df[labeled_df[\"Nicho Tech\"] != \"Não listado\"].reset_index(drop=True)\n",
    "\n",
    "if df.shape[0] != df_copy.shape[0]:\n",
    "    labeled_df = pd.merge(left=df_copy, right=labeled_df, how=\"inner\", on=\"cnpj\")\n",
    "else:\n",
    "    labeled_df = pd.merge(left=df, right=labeled_df, how=\"inner\", on=\"cnpj\")\n",
    "\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79005de",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c28107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_df = labeled_df[[\"url\", \"host\", \"cnpj\", \"raiz_cnpj\", \"nome\", \"cnae\", \"Segmento\", \"Nicho Tech\"]]\n",
    "# labeled_df = labeled_df.rename(columns={\"Nicho Tech_y\": \"Nicho Tech\"})\n",
    "labeled_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_df = labeled_df[\n",
    "#     ['cnpj',\n",
    "#  'nome',\n",
    "#  'Situacao cadastral',\n",
    "#  'CNAE',\n",
    "#  'host',\n",
    "#  'url',\n",
    "#  'Segmento',\n",
    "#  'Subsegmento',\n",
    "#  'Nicho Tech']\n",
    "# ]\n",
    "\n",
    "labeled_df.to_csv(\"../data/iugu_enrichment_chatgpt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01689183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driva_ecomm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
